{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un détecteur de distanciation sociale COVID-19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Réalisé par : Mariam Loukili"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Importer les modèles suivants : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance as dist\n",
    "import numpy as np\n",
    "import imutils\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fixer les seuils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_conf = 0.5\n",
    "min_distance = 60\n",
    "nms_thresh = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Définir la méthode people_detection() pour détecter seulement les personnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def people_detection(img, net, classes) :\n",
    "    #Extraire la hauteu et la largeur et initialiser la liste results\n",
    "    height, width, _ = img.shape\n",
    "    results = []\n",
    "    \n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255, (608,608), (0,0,0), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "    layersOutputs = net.forward(output_layers_names)\n",
    "    \n",
    "   # Initialiser les listes\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    centroids = []\n",
    "    class_ids = []\n",
    "    \n",
    "    # Boucler sur chacune de layer Outputs \n",
    "    for output in layersOutputs:\n",
    "        # Boucler sur chacune des détections\n",
    "        for detection in output:\n",
    "            # Extraire la classe ID et la confiance (c'est-à-dire la probabilité) de la détection de l'objet en cours\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            # Vérifier que le minimum de confiance est respecté\n",
    "            if confidence > min_conf:\n",
    "                \n",
    "                # En tenant compte que YOLO renvoie en fait les coordonnées du centre (x, y) du bounding box,\n",
    "                #suivies de la largeur et de la hauteur du cadre d'objet.\n",
    "                center_x =  int(detection[0]*width)\n",
    "                center_y =  int(detection[1]*height)\n",
    "                w = int(detection[2]*width)\n",
    "                h = int(detection[3]*height)\n",
    "                \n",
    "                # Utiliser les coordonnées du centre (x, y) pour obtenir le coin supérieur et le coin gauche du cadre d'objet.\n",
    "                x = int(center_x - w/2)\n",
    "                y = int(center_y - h/2)\n",
    "                \n",
    "                # Mettre à jour les listes de coordonnées de bounding box, classe IDs ,de centroïdes et de confidences\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append((float(confidence)))\n",
    "                class_ids.append(class_id)\n",
    "                centroids.append((center_x,center_y))\n",
    "                \n",
    "    # Appliquer une suppression non-maxima pour supprimer les bounding box faibles.\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, min_conf, nms_thresh)\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    colors = np.random.uniform(0, 255, size=(len(boxes), 3))\n",
    "    \n",
    "    # Boucler sur les index que nous gardons\n",
    "    for i in indexes.flatten():\n",
    "        x,y,w,h = boxes[i]\n",
    "        label= str(classes[class_ids[i]])\n",
    "        \n",
    "        # En s'assurant que l'objet détecté est une personne \n",
    "        if label == 'person': \n",
    "            confidence =str(round(confidences[i]*100, 2))\n",
    "            \n",
    "            # Mettre à jour la liste \"result\" pour qu'elle comprenne la probabilité de prédiction de la personne, \n",
    "            #les coordonnées de bounding boxet les centroïdes. \n",
    "            r = (confidence, (x, y, x+w, y+h), centroids[i])\n",
    "            results.append(r)\n",
    "            \n",
    "    # Retourner la liste des résultats\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Calculer la distance entre chaque couple de personnes. Puis vérifier si la distance est inférieure au minimum distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] accessing video stream...\n",
      "Fin avec Entrer\n"
     ]
    }
   ],
   "source": [
    "#Charger notre détecteur d'objets YOLOv3 formé sur le dataset COCO (80 classes)\n",
    "net = cv2.dnn.readNet('yolov3.weights', 'yolov3.cfg')\n",
    "# Extraire les noms des objets du fichier coco et les ajouter à la liste \"classes\".\n",
    "classes = []\n",
    "with open('coco.names', 'r') as f:\n",
    "    classes = f.read().splitlines()\n",
    "\n",
    "# Lire la video\n",
    "print(\"[INFO] accessing video stream...\")\n",
    "cap = cv2.VideoCapture('video.mp4')\n",
    "\n",
    "# En boucle sur les images de la vidéo !\n",
    "while True:\n",
    "    # lire l'image suivante du fichier\n",
    "    result, img = cap.read()\n",
    "    if result==False:  # tester s'il y a une image ou non dans la video\n",
    "        print(\"Fin de la video\")\n",
    "        break\n",
    "\n",
    "    #  redimensionner l'image et appeler la méthode people_detection() \n",
    "    img = imutils.resize(img, width=900)\n",
    "    results = people_detection(img, net, classes)\n",
    "\n",
    "    # Initialiser l'ensemble des gens qui sont proches les uns des autres, sans respecter la distance sociale minimum.  \n",
    "    proche = set()\n",
    "\n",
    "    # S'assurer qu'il y a au moins deux personnes détectées (nécessaire pour calculer la distance)\n",
    "    if len(results) >= 2:\n",
    "        # Extraire tous les centroïdes de la list \"results\" et calculer les distances euclidiennes entre toutes\n",
    "        #les paires de centroïdes.\n",
    "        centroids = np.array([r[2] for r in results])\n",
    "        D = dist.cdist(centroids, centroids, metric=\"euclidean\")\n",
    "\n",
    "        for i in range(0, D.shape[0]):\n",
    "            for j in range(i + 1, D.shape[1]):\n",
    "                # Vérifier si la distance entre deux paires de centroïdes est inférieure au nombre de pixels configuré\n",
    "                if D[i, j] < min_distance:\n",
    "                    # Mettre à jour notre set \"proche\" avec les index des paires de centroïdes.\n",
    "                    proche.add(i)\n",
    "                    proche.add(j)\n",
    "\n",
    "    # Boucler sur \"result\"\n",
    "    for (i, (prob, bbox, centroid)) in enumerate(results):\n",
    "        # Extraire les bounding box et les coordonnées du centroïde, puis initialiser la couleur de l'annotation\n",
    "        (startX, startY, endX, endY) = bbox\n",
    "        (cX, cY) = centroid\n",
    "        color = (0, 255, 0)\n",
    "\n",
    "        # Si la paire d'indices existe dans l'ensemble des personnes proches, alors modifiez la couleur.\n",
    "        if i in proche:\n",
    "            color = (0, 0, 255)\n",
    "\n",
    "        # Dessiner bounding box autour de la personne.\n",
    "        cv2.rectangle(img, (startX, startY), (endX, endY), color, 2)\n",
    "        # Dessiner le centroïde de la personne.\n",
    "        cv2.circle(img, (cX, cY), 2, color, 1)\n",
    "\n",
    "    # Afficher le nombre total des gens qui violent la distance sociale\n",
    "    text = \"Distanciation sociale insuffisante {}\".format(len(proche))\n",
    "    cv2.putText(img, text, (5, img.shape[0] - 25),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 0, 255), 2)\n",
    "\n",
    "   # Afficher les résultats sur l'écran\n",
    "    cv2.imshow(\"Frame\", img)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # si la touche \"Entrée\" a été appuyée, sortir de la boucle.\n",
    "    if key == 13:\n",
    "        print(\"Fin avec Entrer\")\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
